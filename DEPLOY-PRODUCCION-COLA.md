# üöÄ Gu√≠a de Deploy a Producci√≥n - Sistema de Cola

**Fecha:** 2025-11-21
**Commit:** 72b069d

---

## ‚úÖ Paso 1: C√≥digo Subido a GitHub

El c√≥digo ya fue pusheado a GitHub:
```
Commit: 72b069d
Branch: main
Archivos: 15 files changed, 2930 insertions(+)
```

Railway deber√≠a estar desplegando autom√°ticamente.

---

## üîß Paso 2: Configurar Variables de Entorno en Railway

### Variables Requeridas:

```bash
GEMINI_API_KEY=tu_clave_de_google_gemini
GEMINI_MODEL=gemini-2.5-flash-image
```

### C√≥mo Agregar Variables en Railway:

1. **Ir a Railway Dashboard:**
   - https://railway.app/dashboard

2. **Seleccionar el Proyecto:**
   - Click en "Inventario-3G" o tu proyecto backend

3. **Ir a Variables:**
   - Click en la pesta√±a "Variables"

4. **Agregar Variables:**
   ```
   Variable Name: GEMINI_API_KEY
   Value: [Tu API Key de Google AI Studio]
   ```

   ```
   Variable Name: GEMINI_MODEL
   Value: gemini-2.5-flash-image
   ```

5. **Guardar y Redeploy:**
   - Click en "Add" para cada variable
   - Railway redesplegar√° autom√°ticamente

### Obtener GEMINI_API_KEY:

1. Ir a: https://aistudio.google.com/app/apikey
2. Click en "Create API Key"
3. Seleccionar proyecto o crear uno nuevo
4. Copiar la clave generada

---

## üóÑÔ∏è Paso 3: Ejecutar Migraci√≥n en Producci√≥n

### Opci√≥n A: Ejecutar desde Railway CLI

```bash
# Conectarse a Railway
railway link

# Ejecutar migraci√≥n
railway run node migrations/run-queue-migration.js
```

### Opci√≥n B: Ejecutar con DATABASE_URL directamente

```bash
# Obtener DATABASE_URL de Railway
railway variables

# Ejecutar localmente conect√°ndose a producci√≥n
DATABASE_URL="postgresql://..." node migrations/run-queue-migration.js
```

### Opci√≥n C: Usar el Comando Run de Railway (Recomendado)

1. Ir a Railway Dashboard
2. Click en tu servicio backend
3. Ir a la pesta√±a "Settings"
4. En "Deploy" ‚Üí "Custom Start Command", temporalmente cambiar a:
   ```
   node migrations/run-queue-migration.js && node server.js
   ```
5. Guardar y esperar redeploy
6. Una vez ejecutada la migraci√≥n, revertir a:
   ```
   node server.js
   ```

**Nota:** La migraci√≥n solo necesita ejecutarse UNA vez.

---

## ‚úÖ Paso 4: Verificar Deploy

### 4.1 Verificar Logs de Railway:

```bash
railway logs
```

Buscar:
```
‚úÖ Conexi√≥n a base de datos establecida correctamente
‚úÖ Modelos sincronizados con la base de datos
üöÄ [Cola] Worker de procesamiento de im√°genes iniciado
   üëÄ [Cola] Esperando art√≠culos en la cola...
```

### 4.2 Verificar Endpoints:

```bash
# Obtener URL de producci√≥n
URL_BACKEND="https://tu-proyecto.railway.app"

# 1. Verificar servidor
curl $URL_BACKEND/

# 2. Login
TOKEN=$(curl -s -X POST $URL_BACKEND/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"admin@3g.com","password":"admin123"}' \
  | jq -r '.data.token')

# 3. Verificar endpoint de estado de cola
curl -s -X GET "$URL_BACKEND/api/articulos/processing-queue/status" \
  -H "Authorization: Bearer $TOKEN" \
  | jq

# Debe devolver:
{
  "success": true,
  "data": {
    "stats": {
      "pendientes": 0,
      "procesando": 0,
      "completados": 0,
      "fallidos": 0,
      "total": 0
    },
    "articuloActual": null
  }
}
```

---

## üåê Paso 5: Verificar Frontend en Vercel

### 5.1 Deploy Autom√°tico de Vercel:

Vercel deber√≠a desplegar autom√°ticamente desde GitHub.

### 5.2 Verificar URL de Producci√≥n:

```bash
# Frontend URL
https://inventario-3g.vercel.app

# P√°gina de procesamiento masivo
https://inventario-3g.vercel.app/procesamiento-masivo
```

### 5.3 Probar Funcionalidad:

1. Login con admin@3g.com / admin123
2. Click en "Procesamiento IA" en el men√∫
3. Seleccionar art√≠culos
4. Click en "Procesar"
5. Ver estado en tiempo real

---

## üß™ Paso 6: Prueba End-to-End en Producci√≥n

### Prueba Completa:

```bash
# 1. Login
TOKEN=$(curl -s -X POST https://tu-backend.railway.app/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"admin@3g.com","password":"admin123"}' \
  | jq -r '.data.token')

# 2. Listar art√≠culos con imagen
curl -s -X GET "https://tu-backend.railway.app/api/articulos?activo=true" \
  -H "Authorization: Bearer $TOKEN" \
  | jq '.data.articulos[] | select(.imagen_url != null) | {id, nombre}'

# 3. Agregar art√≠culo a la cola (ejemplo: ID 115)
curl -s -X POST "https://tu-backend.railway.app/api/articulos/batch-process-images" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"articuloIds":[115],"prioridad":0}' \
  | jq

# 4. Ver estado de la cola (repetir cada 5s)
watch -n 5 'curl -s -X GET "https://tu-backend.railway.app/api/articulos/processing-queue/status" \
  -H "Authorization: Bearer $TOKEN" | jq'

# 5. Ver historial cuando termine
curl -s -X GET "https://tu-backend.railway.app/api/articulos/processing-queue/history" \
  -H "Authorization: Bearer $TOKEN" \
  | jq
```

---

## üîç Troubleshooting

### Problema 1: Worker no se inicia
**S√≠ntomas:** No se procesan art√≠culos en la cola

**Soluci√≥n:**
1. Verificar logs: `railway logs`
2. Buscar error: `[Cola] Worker de procesamiento`
3. Verificar que GEMINI_API_KEY est√© configurada

### Problema 2: Error "table does not exist"
**S√≠ntomas:** Error al acceder a endpoints de cola

**Soluci√≥n:**
1. Ejecutar migraci√≥n en producci√≥n (Paso 3)
2. Verificar en logs: `‚úÖ Tabla image_processing_queue creada`

### Problema 3: Error de Gemini API
**S√≠ntomas:** Art√≠culos quedan en estado "failed"

**Soluci√≥n:**
1. Verificar GEMINI_API_KEY en Railway variables
2. Verificar que la API Key sea v√°lida en Google AI Studio
3. Verificar cuota/l√≠mites en Google Cloud Console

### Problema 4: CORS Error en Frontend
**S√≠ntomas:** Frontend no puede conectar con backend

**Soluci√≥n:**
1. Verificar FRONTEND_URL en Railway:
   ```
   FRONTEND_URL=https://inventario-3g.vercel.app
   ```
2. Verificar en backend/server.js que se agregue a allowedOrigins

---

## üìä Monitoreo Post-Deploy

### M√©tricas a Monitorear:

1. **Logs de Worker:**
   ```bash
   railway logs --filter "Cola"
   ```

2. **Estado de la Cola:**
   - Visitar: https://tu-frontend.vercel.app/procesamiento-masivo
   - Ver panel de estad√≠sticas

3. **Costos de Gemini:**
   - Google Cloud Console ‚Üí APIs & Services ‚Üí Gemini AI
   - Monitorear uso mensual

4. **Base de Datos:**
   ```sql
   SELECT COUNT(*) FROM image_processing_queue WHERE estado = 'pending';
   SELECT COUNT(*) FROM image_processing_queue WHERE estado = 'failed';
   ```

---

## ‚úÖ Checklist de Deploy

- [x] C√≥digo pusheado a GitHub
- [ ] Variables de entorno configuradas en Railway
  - [ ] GEMINI_API_KEY
  - [ ] GEMINI_MODEL
- [ ] Migraci√≥n ejecutada en producci√≥n
- [ ] Worker iniciado correctamente
- [ ] Frontend desplegado en Vercel
- [ ] Prueba end-to-end exitosa
- [ ] Logs verificados
- [ ] Endpoints funcionando

---

## üéâ Deploy Completado

Una vez completados todos los pasos:

‚úÖ **Backend:** https://tu-proyecto.railway.app
‚úÖ **Frontend:** https://inventario-3g.vercel.app
‚úÖ **Procesamiento IA:** https://inventario-3g.vercel.app/procesamiento-masivo

**Sistema 100% Funcional en Producci√≥n! üöÄ**

---

## üìû Soporte

Si hay problemas durante el deploy:

1. Verificar logs de Railway: `railway logs`
2. Verificar logs de Vercel: Vercel Dashboard ‚Üí Deployments ‚Üí View Logs
3. Verificar variables de entorno
4. Verificar que la migraci√≥n se ejecut√≥

---

**√öltima actualizaci√≥n:** 2025-11-21
**Versi√≥n:** 1.0
**Estado:** Listo para producci√≥n
